{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-28T15:04:27.160718Z","iopub.status.busy":"2024-07-28T15:04:27.160298Z","iopub.status.idle":"2024-07-28T15:04:48.407326Z","shell.execute_reply":"2024-07-28T15:04:48.405581Z","shell.execute_reply.started":"2024-07-28T15:04:27.160684Z"},"trusted":true},"outputs":[],"source":["import torch \n","import torch.nn as nn\n","!pip install -q torch-summary\n","from torchsummary import summary \n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T15:23:50.898396Z","iopub.status.busy":"2024-07-28T15:23:50.897796Z","iopub.status.idle":"2024-07-28T15:23:50.917803Z","shell.execute_reply":"2024-07-28T15:23:50.916209Z","shell.execute_reply.started":"2024-07-28T15:23:50.898348Z"},"trusted":true},"outputs":[],"source":["class Inception(nn.Module):\n","    def __init__(self, fan_in, n_1x1, n_1x1_b4_3x3, n_3x3, n_1x1_b4_5x5, n_5x5, n_1x1_pool):\n","        super().__init__()\n","        self._conv_block = ConvBlock\n","        self.block1 = self._conv_block(fan_in, n_1x1, kernel_size = 1)\n","        self.block2 = nn.Sequential(\n","            self._conv_block(fan_in, n_1x1_b4_3x3, kernel_size = 1),\n","            self._conv_block(n_1x1_b4_3x3, n_3x3, kernel_size = 3, padding = 'same')\n","        )\n","        self.block3 = nn.Sequential(\n","            self._conv_block(fan_in, n_1x1_b4_5x5, kernel_size = 1),\n","            self._conv_block(n_1x1_b4_5x5, n_5x5, kernel_size = 5, padding = 'same')\n","        )\n","        self.block4 = nn.Sequential(\n","            nn.MaxPool2d(3, stride = 1, ceil_mode = True, padding = 1),\n","            self._conv_block(fan_in, n_1x1_pool, kernel_size = 1)\n","        )\n","    \n","    def forward(self, x):\n","        x1 = self.block1(x) #(1, 64, 28, 28)\n","        x2 = self.block2(x) #(1, 128, 28, 28)\n","        x3 = self.block3(x) #(1, 32, 28, 28)\n","        x4 = self.block4(x) #(1, 32, 28, 28)\n","        \n","        \n","        return torch.cat([x1, x2, x3, x4], dim = 1)\n","\n","        \n","        \n","#     def _conv_block(self, fan_in, fan_out, **kwargs):\n","#         block = nn.Sequential(\n","#             nn.Conv2d(fan_in, fan_out, bias = False, **kwargs),\n","#             nn.BatchNorm2d(fan_out),\n","#             nn.ReLU()\n","#         )\n","#         return block\n","\n","\n","    \n","class ConvBlock(nn.Module): #making this a function of the Inception class is infeasible since we need to use this in the GoogLeNet class as well.\n","    def __init__(self, fan_in, fan_out, kernel_size, **kwargs):\n","        super().__init__()\n","        self.block = nn.Sequential(\n","            nn.Conv2d(fan_in, fan_out, kernel_size, bias = False, **kwargs),\n","            nn.BatchNorm2d(fan_out),\n","            nn.ReLU()\n","        )\n","    \n","    def forward(self, x):\n","        out = self.block(x)\n","        return out"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T15:23:53.317255Z","iopub.status.busy":"2024-07-28T15:23:53.316810Z","iopub.status.idle":"2024-07-28T15:23:53.338992Z","shell.execute_reply":"2024-07-28T15:23:53.337717Z","shell.execute_reply.started":"2024-07-28T15:23:53.317217Z"},"trusted":true},"outputs":[],"source":["class GoogLeNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        inception_block = Inception\n","        conv_block = ConvBlock\n","        max_pool = nn.MaxPool2d(3, stride = 2, ceil_mode = True)\n","        lrn = nn.LocalResponseNorm(5, k = 2)\n","        \n","        self.conv1 = conv_block(3, 64, 7, stride = 2, padding = 3) #(1, 64, 112, 112)\n","        self.maxpool1 = max_pool #(1, 64, 56, 56)\n","        self.lrn1 = lrn #(1, 64, 56, 56)\n","        self.conv2_a = conv_block(64, 64, 1) #(1, 64, 56, 56)\n","        self.conv2_b = conv_block(64, 192, 3, padding = 'same') #(1, 192, 56, 56)\n","        self.lrn2 = lrn #(1, 192, 56, 56)\n","        self.maxpool2 = max_pool #(1, 192, 28, 28)\n","        self.inception1 = inception_block(192, 64, 96, 128, 16, 32, 32) #(1, 256, 28, 28)\n","        self.inception2 = inception_block(256, 128, 128, 192, 32, 96, 64) #(1, 480, 28, 28)\n","        self.maxpool3 = max_pool #(1, 480, 14, 14)\n","        self.inception3 = inception_block(480, 192, 96, 208, 16, 48, 64) #(1, 512, 14, 14)\n","        self.inception4 = inception_block(512, 160, 112, 224, 24, 64, 64) #(1, 512, 14, 14)\n","        self.inception5 = inception_block(512, 128, 128, 256, 24, 64, 64) #(1, 512, 14, 14)\n","        self.inception6 = inception_block(512, 112, 144, 288, 32, 64, 64) #(1, 528, 14, 14)\n","        self.inception7 = inception_block(528, 256, 160, 320, 32, 128, 128) #(1, 832, 14, 14)\n","        self.maxpool4 = max_pool #(1, 832, 7, 7)\n","        self.inception8 = inception_block(832, 256, 160, 320, 32, 128, 128) #(1, 832, 7, 7)\n","        self.inception9 = inception_block(832, 384, 192, 384, 48, 128, 128) #(1, 1024, 7, 7)\n","        self.avgpool1 = nn.AvgPool2d(7, stride = 1) #(1, 1024, 1, 1)\n","        self.ln1 = nn.Linear(1024, 1000)\n","    \n","    def forward(self, x):\n","        assert len(x.shape) == 4, f'Input tensor of dimension {x.shape}, requires to be 4.' # we have the BatchNorm layers in the Inception module hence we need a batch dimension\n","        x = self.conv1(x)\n","        x = self.maxpool1(x)\n","        x = self.lrn1(x)\n","        x = self.conv2_a(x)\n","        x = self.conv2_b(x)\n","        x = self.lrn2(x)\n","        x = self.maxpool2(x)\n","        x = self.inception1(x)\n","        x = self.inception2(x)\n","        x = self.maxpool3(x)\n","        x = self.inception3(x)\n","        x = self.inception4(x)\n","        x = self.inception5(x)\n","        x = self.inception6(x)\n","        x = self.inception7(x)\n","        x = self.maxpool4(x)\n","        x = self.inception8(x)\n","        x = self.inception9(x)\n","        x = self.avgpool1(x)\n","        x = F.dropout(x, 0.4)\n","        x = x.view(-1, 1024)\n","        x = self.ln1(x)\n","        x = F.softmax(x, dim = -1)\n","        \n","        return x\n","        \n","        \n","        \n","        \n","        \n","        \n","        \n","   "]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T15:24:06.721589Z","iopub.status.busy":"2024-07-28T15:24:06.721042Z","iopub.status.idle":"2024-07-28T15:24:07.084569Z","shell.execute_reply":"2024-07-28T15:24:07.083163Z","shell.execute_reply.started":"2024-07-28T15:24:06.721555Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([1, 1000])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.rand((1, 3, 224, 224), generator = torch.Generator().manual_seed(2))\n","model = GoogLeNet()\n","model(x).shape"]},{"cell_type":"markdown","metadata":{},"source":["The end results we find matches the one mentioned in the paper, signifying that our approach has been accurate. Note that the original paper involves an `Auxilliary Inception` part which has not been included in this version of GoogLeNet implementation. "]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
